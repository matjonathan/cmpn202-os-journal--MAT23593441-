# Week 2 – Security Planning & Testing Methodology

## 1. Weekly Overview

**Focus of this week:**  
Plan security controls and performance testing strategy before heavy configuration.


---

## 2. Weekly Objectives

By the end of this week, I aimed to:

1. Design a performance testing methodology for the server.
2. Identify security controls I will implement (firewall, SSH hardening, MAC, etc.).
3. Create an initial threat model for my virtual environment.
4. Decide which metrics and tools I will use for monitoring.

---

## 3. Planned Performance Testing Strategy

### 3.1 Metrics to Collect

The following system and application-level metrics will be collected to evaluate operating system performance under different workloads:

-CPU usage:

Measured using top, htop, and mpstat to observe overall CPU utilisation, per-core usage, and system load averages during idle and stressed conditions.

-Memory usage:

Measured using free -h and vmstat to analyse total, used, and available memory, as well as paging and swap activity under load.

-Disk I/O performance:

Measured using iostat to observe read/write throughput and disk wait times. Additional synthetic I/O tests will be generated using tools such as dd or fio where appropriate.

-Network throughput and latency:

Measured using ping for latency and packet loss, and iperf3 for bandwidth and throughput testing between the workstation and the server.

-Application-level performance metrics:

Measured using tools such as curl, ab, or wrk to capture response times and request handling performance for server-based applications.

### 3.2 Tools & Rationale

| Tool      | Purpose                    | Why chosen                         |
|-----------|----------------------------|------------------------------------|
| top / htop  | CPU and memory monitoring        | Provides real-time system resource visibility and is widely used in Linux system administration                           |
| free -h / vmstat  | Memory and system statistics            | Lightweight tools that clearly display memory usage, paging, and system activity                           |
| iostat  | Disk I/O performance             | Allows detailed analysis of disk read/write throughput and I/O wait times                          |
| ping / iperf3  | Network latency and throughput   | Industry-standard tools for measuring network performance                           |

### 3.3 Baseline vs Load Tests

- **Baseline tests:**

Conditions:
  
The system will be in an idle state with only essential services running and an active SSH session from the workstation.

Goals:
  
To measure background resource usage, establish normal operating behaviour, and identify baseline system noise levels.

- **Load tests:**
  - How I will generate load: Load will be generated by running selected applications and services, executing benchmarking tools, and performing controlled stress operations where appropriate.
  - Duration: Each test will run for a fixed duration (e.g. 5–10 minutes) to ensure consistent and comparable results.
  - Repetitions: Each test scenario will be repeated multiple times (e.g. three runs per scenario) to allow averaging of results and reduce the impact of transient system fluctuations.

This structured approach enables accurate comparison between idle and stressed system behaviour and supports meaningful performance analysis in later phases of the coursework.
---

## 4. Security Configuration Plan

### 4.1 SSH Hardening Plan

To reduce the attack surface of the server and secure remote administration, the following SSH hardening measures are planned:

- Use key-based authentication instead of password-based authentication to prevent brute-force attacks.
- Disable root login over SSH to ensure administrative access is performed through a non-root user with sudo privileges.
- Change the default SSH port from 22 to a non-standard port to reduce exposure to automated scanning (used as a supplementary control).

**Planned configuration settings in `/etc/ssh/sshd_config`:**

PermitRootLogin no
PasswordAuthentication no
PubkeyAuthentication yes
AllowUsers adminuser
LoginGraceTime 30
MaxAuthTries 3


These settings enforce strong authentication, limit login attempts, and minimise the risk of unauthorised access.

---

### 4.2 Firewall Strategy

**Firewall tool:** UFW (Uncomplicated Firewall)

UFW is selected because it is lightweight, command-line driven, and fully supported on Ubuntu Server, making it suitable for controlled and auditable firewall management.

**Firewall policy:**

- Default incoming traffic: **deny**
- Default outgoing traffic: **allow**
- Allow SSH access only from the trusted workstation IP address `192.168.56.10`
- Deny all other inbound traffic by default

This configuration ensures that the server is only accessible from the authorised workstation while preventing all other unsolicited network traffic.

---

### 4.3 Mandatory Access Control (MAC)

**Planned MAC framework:** AppArmor  
**Mode:** Enforcing

AppArmor is chosen because it is enabled by default on Ubuntu Server and provides application-level confinement using human-readable security profiles.

The main objective of using mandatory access control is to confine services so that, if one service is compromised, its ability to access unauthorised files, system resources, or other services is restricted. This limits the overall impact of a security breach.

---

### 4.4 Automatic Updates and Additional Security Controls

- Automatic security updates will be configured using `unattended-upgrades` to ensure critical security patches are applied without manual intervention.
- Intrusion and brute-force protection will be implemented using `fail2ban`, which monitors authentication activity and automatically blocks IP addresses exhibiting repeated failed login attempts.
- System logging will be used to support later security auditing and analysis. The following logs will be monitored:
  - `/var/log/auth.log` – authentication and SSH activity
  - `/var/log/syslog` – general system events and service activity
  - `fail2ban` logs – intrusion detection events

These controls collectively strengthen system security while maintaining a professional headless server administration model.


---

## 5. Threat Model

### 5.1 Environment Description

The system is deployed in an isolated VirtualBox environment with the following characteristics:

- The server is reachable only from the workstation via a host-only network.
- NAT networking is used solely to provide outbound Internet access for package updates and does not permit inbound Internet connections.
- There is a single student administrator account with `sudo` privileges.
- All system administration is performed remotely over SSH.

This controlled environment significantly reduces external attack vectors but still requires strong internal security controls.

---

### 5.2 Threats and Mitigations

#### Threat 1: Brute-Force SSH Attack

**Scenario:**  
An attacker attempts to gain access by repeatedly guessing SSH login credentials.

**Impact:**  
Successful compromise could result in full administrative access to the server.

**Likelihood in this environment:**  
Low, due to the isolated host-only network and restricted SSH access, but still possible through misconfiguration or internal threats.

**Planned mitigations:**
- Enforce SSH key-based authentication.
- Disable password-based SSH logins.
- Disable root login over SSH.
- Restrict SSH access to a single trusted workstation IP using the firewall.
- Implement `fail2ban` to monitor and block repeated failed login attempts.

---

#### Threat 2: Misconfigured Firewall Rules

**Scenario:**  
Firewall rules are incorrectly configured, unintentionally exposing unnecessary ports or services on the host-only network.

**Impact:**  
Increased attack surface and potential unauthorised access to services.

**Likelihood in this environment:**  
Medium, as firewall misconfiguration is a common administrative error.

**Planned mitigations:**
- Apply a default deny policy for all incoming traffic.
- Explicitly allow only required services (SSH).
- Maintain a documented firewall ruleset.
- Regularly verify firewall status using commands such as `sudo ufw status`.

---

#### Threat 3: Privilege Escalation

**Scenario:**  
A user account misuses sudo privileges or exploits incorrectly configured sudo rules to gain root-level access.

**Impact:**  
Complete system compromise and loss of system integrity.

**Likelihood in this environment:**  
Low, as only one administrative user exists, but still possible due to configuration errors.

**Planned mitigations:**
- Follow the principle of least privilege for sudo access.
- Carefully configure and audit `/etc/sudoers`.
- Enforce strong authentication using SSH keys.
- Avoid unnecessary elevation of privileges during routine administration.

---

#### Threat 4: Unpatched Software Vulnerabilities

**Scenario:**  
Outdated packages contain known vulnerabilities that can be exploited.

**Impact:**  
Potential remote code execution, data compromise, or service disruption.

**Likelihood in this environment:**  
Medium, as vulnerabilities regularly emerge in system packages.

**Planned mitigations:**
- Enable automatic security updates using `unattended-upgrades`.
- Regularly review installed packages and update as required.
- Conduct periodic security audits in later phases.

---

This threat model informs the security configuration decisions implemented in later weeks and ensures that security controls are proportionate to the identified risks.

---

## 6. Mapping to Coursework Phases

This week focused on planning and design, which directly supports the implementation and evaluation phases later in the coursework.

**Links to Weeks 4–5 (Security Implementation):**  
The SSH hardening plan, firewall strategy, mandatory access control decisions, fail2ban configuration, and automatic update strategy defined in this week will be implemented and documented during Weeks 4 and 5. Having these controls planned in advance reduces configuration errors and ensures consistent security implementation.

**Links to Week 6 (Performance Evaluation):**  
The performance testing strategy developed this week defines the metrics, tools, and testing methodology that will be used during performance evaluation. This ensures that baseline and load testing in Week 6 are structured, repeatable, and comparable.

**Links to Week 7 (Security Audit):**  
The threat model created in this week informs the security audit conducted in Week 7. Identified threats directly guide what is examined using tools such as Lynis and nmap, as well as which logs and configurations are prioritised during the audit process.

---

## 7. Problems Encountered and Solutions

**Problem:**  
Uncertainty around which performance monitoring tools and metrics were most appropriate for a headless Linux server.

**What confused me:**  
There are many available monitoring tools, and online guidance often recommends advanced or overlapping utilities, making it difficult to identify which tools were suitable for this coursework and environment.

**How I resolved it:**  
I focused on selecting widely used, lightweight command-line tools that are commonly available on Ubuntu Server by default. I reviewed official documentation and briefly tested tools such as `top`, `free`, and `iostat` to understand their outputs before finalising the monitoring plan.

---

## 8. Reflection (Week 2)

Developing a threat model significantly changed my initial Week 1 system design by highlighting that security planning must precede configuration rather than being applied retrospectively. Identifying realistic threats clarified why controls such as firewall restrictions, SSH hardening, and mandatory access control are essential even in an isolated VirtualBox environment.

This week reinforced the importance of planning both security and performance testing before implementing system changes. Defining metrics, tools, and methodologies in advance reduces ambiguity and ensures that later testing produces meaningful and comparable results.

The structured planning completed this week will make Weeks 4–7 more efficient by providing clear implementation targets and evaluation criteria. After considering the identified threats, I would already refine my original plan by enforcing stricter SSH controls and prioritising automated security updates earlier in the system lifecycle.
